> AI是一个跨学科的技术领域，发展历程坎坷。从早期的理论探索到今天的实际应用，如今的AI在各行各业中发挥着越来越重要的作用。

AI的发展历史特别悠久，最近两年ChatGPT更是引爆了这一概念。AI领域里的生僻、拗口、吓人的名词更是一大堆，每个拿出来都能吓人。先不管这些唬人的名词，本篇，我们先从一个AI应用开发者的角度总览一把AI的发展脉络。

## 1、AI发展起源

相信朋友们肯定听过大名鼎鼎的“**图灵测试**”。这是由被誉为计算机科学与人工智能之父的“艾伦·图灵”于1950年提出的一项测试标准，用来评估机器能否表现出与人类智能水平相当的一项测试标准。

同期，1956年，在**达特茅斯**会议上，“人工智能”这一术语首次被提出，这标志着AI作为一个**独立学科**的诞生。

20世纪60年代和70年代，AI研究取得了一些初步成果，比如人工智能领域里的**专家系统**。然而，由于计算能力和数据获取的限制，AI的应用非常有限，许多早期的希望都落空了。

## 2、AI发展的3个流派

早期AI的发展有3个流派，分别是：符号主义、连接主义、行为主义。他们之间也并非独立，而是相互借鉴发展，最终才有了今天的成效。

### 符号主义

早期的AI研究主要集中在符号主义，通过逻辑推理和规则系统来模拟人类的智能行为。

**符号主义**被称为**基于规则**的人工智能或经典人工智能。符号主义认为，智能行为可以通过操作符号来实现，这些符号可以表示世界中的对象、概念、关系等。符号主义的核心在于使用符号来表示世界的不同方面，并通过一套规则来操作这些符号，这种方法依赖于明确定义的知识和推理过程。

符号主义技术包括：知识图谱、语义网络、决策树等。早期的人工智能进步就是利用符号主义来建模关系和传递意义。

- 符号是用于表示对象、概念或关系的抽象标记。例如，"猫"这个符号可以表示现实世界中的猫。
- 规则是用于操作符号的逻辑表达式或算法。例如，"如果A是B的父亲，且B是C的父亲，那么A是C的祖父"就是一个规则。
- 符号主义使用符号和规则来表示知识。常见的知识表示方法包括：规则、语义网、框架、生产系统等。
- 符号主义系统通过应用规则对符号进行操作，从而进行推理和决策。例如，通过一系列规则推导出某个结论。

**符号主义的例子**

一个经典的符号主义系统是**专家系统**。专家系统是人工智能领域的一个重要分支，专家系统就像一个特定领域的知识大全，它囊括了该领域的专业知识，并且能够根据这些知识对问题进行推理和判断，给出专业的建议和解决方案。

所以它的设计架构就分为了两部分，一部分是知识库，用于存储各种专业知识，另一部分是推理引擎。负责根据知识库的内容进行分分析和推理。这两部分系统共同组成了这个专家的大脑。

以下是一个简单的`诊断疾病`专家系统示例：

1. **知识库**：包含医学知识的符号和规则。
    - 符号：发热、咳嗽、头痛、流感、感冒等。
    - 规则：
        - 如果有发热和咳嗽，那么可能是流感。
        - 如果有头痛和流鼻涕，那么可能是感冒。
2. **推理引擎**：应用规则对输入的症状进行推理。
    - 输入症状：发热、咳嗽。
    - 推理过程：
        - 根据规则1，如果有发热和咳嗽，那么可能是流感。
    - 输出结论：可能是流感。

### 连接主义

随着越来越多的人开始反思符号主义的局限性，以及现实中的AI系统频频掉链子。研究者意识到，要创造真正的人工智能，必须换一条更接近人类本质的路子走。于是，一个叫连接主义的流派开始崛起。

**连接主义**是一种自下而上的方法，它模仿人脑及其神经连接，它的观点是从数据中学习关联性，连接主义模型通过经验学习，建立起一种复杂的关联的知识表示，这种知识表示反映了模型对数据的统计理解和预期。我们使用的**神经网络**就是一种典型的联结主义模型，它通过调整神经元之间的连接权重来学习。

从上面的定义可以看出，符号主义更接近于理性主义。这种思想认为理性和逻辑推理是获取知识的主要方式。理性主义者认为，通过逻辑和推理，人们可以发现普遍的真理和原则。

连接主义呢更接近于经验主义，这是另一种哲学思想。认为所有的知识都来源于经验，特别是感官经验。经验主义者认为，通过观察和实验，人们可以了解世界并构建知识。

### 行为主义

**行为主义**强调通过观察和记录行为来研究智能，它通过观察外部环境然后采取行动来学习最佳决策，而不考虑内部心理过程。他在**强化学习**领域中有重要意义，但是在理解和模拟复杂的认知过程方面，存在限制。

### 理性和经验的结合

大多数人都认为，知识的获取需要理性和经验的结合。人工智能的研究也反映了这种综合观点。比如在以神经网络为代表的连接主义当中，虽然主要靠数据驱动学习，但网络的设计和特征的选择却离不开先验知识的指导。而以专家系统为代表的符号主义虽然重视逻辑推理，但也常常利用机器学习算法，从数据中学习和优化知识。

## 3、AI发展的寒冬期

时间线来到了20世纪70年代和80年代，AI经历了所谓的“AI寒冬”。这一时期，研究资金减少，许多项目被迫中止。

进入寒冬期的主要原因包括：

1. **专家系统局限性**：早期AI的符号主义的典型代表是专家系统。当时专家系统的热度毫不亚于今天的大语言模型，然后很快也暴露出局限性。比如为复杂领域构建知识库和制定复杂的规则是非常艰巨的任务。而且这些系统缺乏从经验中学习的能力，只会死记硬背，遇到新问题就束手无策，因此热潮逐渐褪去。
2. **计算能力不足**：早期计算机的性能远不能满足AI算法的需求，导致许多理论无法付诸实践。
3. **数据匮乏**：AI需要大量的数据来训练和验证模型，但当时获取和处理大规模数据的能力有限。
4. **算法局限性**：许多早期的AI算法在处理复杂的现实问题时效果不佳，尤其是在应对不确定性和模糊性方面。

这些瓶颈导致了研究者和投资者对AI的信心下降，使得AI研究进入了一个低谷期。

## 4、AI发展的突破期

时间线来到了20世纪90年代和21世纪初，随着计算机性能的提升、互联网的普及和数据存储技术的进步，AI发展迎来了新的春天，随后神经网络、大语言模型等迎来了爆发式发展。几个关键因素促成了AI的突破：

1. **计算能力提升**：摩尔定律推动了计算能力的指数级增长，使复杂的AI算法可以在合理的时间内执行。
2. **大数据**：互联网的普及带来了前所未有的数据量，这为AI模型的训练提供了丰富的资源。
3. **新算法**：以机器学习和深度学习为代表的新算法极大地提升了AI的性能和应用范围。

简述就是：**算法、算力、数据**。

## 5、NLP自然语言的发展

自然语言处理（Natural Language Processing，NLP）是AI的一个重要分支，致力于让计算机理解和生成人类语言。NLP的发展可以分为以下几个阶段：

1. **起源期**：20世纪10年代到50年代，这个年代最著名的就是提出了**马尔可夫模型**。马尔可夫认为语言之间存在某种关联性，并且可以使用概率模型表示。马尔可夫还在这个阶段提出了著名的**马尔可夫链**。接着香农在马尔可夫链的基础上，研究得出，语言的统计特性可以被建模。通过这个概率模型可以有效地生成语言。这为后来的研究者打开了通过**概率模型生成语言**的思路。
2. **早期符号方法**：20世纪50年代到80年代，NLP主要依赖规则和语法分析，也就是基于规则的形式语言理论。这些方法虽然在一些特定任务上（比如常用规范的中文翻译）取得了一些成功，但在应对复杂和多变的自然语言时会遇到明显的瓶颈。
3. **概率和统计方法**：20世纪90年代，随着计算能力的提升和大规模文本数据的可用，统计方法在NLP中开始占据主导地位。隐马尔可夫模型（HMM）技术在语音识别和文本分类等任务中取得了显著进展。
4. **机器学习和深度学习**：21世纪初，随着计算能力的进一步增强，机器学习和深度学习技术在NLP中得到了广泛应用。尤其是深度学习的发展更是依赖于大幅度提升的算力。这个阶段，深度学习领域的卷积神经网络（CNN）、循环神经网络（RNN）、长短期记忆网络（LSTM）等技术在图像识别、机器翻译、文本生成等任务中表现优异。这个阶段，还有个里程碑的进展，那就是提出了**词向量技术**。词向量技术可以词转成向量，**语义相近的词在向量空间中距离也相近**。
5. **预训练模型和Transformer**：2017年，预训练语言模型和Transformer架构的提出给NPL带来了革命性进展。预训练语言模型的诞生是自然语言处理的一个里程碑。“预训练”一般是将大量的低成本收集的训练数据放在一起，经过某种预训练方法去学习其中的共性，然后在使用特定领域的少量标注数据进行“微调”。Transformer的预训练模型的核心是采用**自注意力机制**，通过自注意力机制挖掘各类特征和重要信息，并能够有效地记忆历史信息。基于Transformer的预训练模型，如BERT、GPT等，通过在大规模语料上进行无监督预训练，然后在特定任务上进行微调，显著提升了NLP任务的性能。

## 6、简述机器学习

机器学习旨在开发和评估能够使计算机从数据集中提取函数的算法。即：让机器从数据集中找到一个合适的函数。

机器学习（Machine Learning，ML）是AI的一个分支，主要关注如何让计算机从数据中学习。与传统的规则系统不同，机器学习算法通过识别数据中的模式来进行预测和决策。常见的机器学习算法包括线性回归、决策树、随机森林、支持向量机（SVM）等。

机器学习的成功应用包括垃圾邮件过滤、图像识别、推荐系统等。这些应用的成功展示了机器学习在处理复杂数据和任务的能力。

## 7、简述深度学习

深度学习（Deep Learning）是机器学习的一个子领域，主要研究多层神经网络的训练和应用。深度学习的核心是卷积神经网络（CNN）和递归神经网络（RNN）。

深度学习的一个重大突破是在图像识别和语音识别领域。2012年，Hinton等人提出的深度卷积神经网络在ImageNet竞赛中取得了显著成绩，开启了深度学习的广泛应用。深度学习的成功依赖于以下几个因素：

1. **大规模数据**：深度学习需要大量的标注数据来训练复杂的模型。
2. **强大的计算能力**：GPU等硬件加速器的出现使得深度学习模型的训练时间大幅缩短。
3. **创新的算法**：如反向传播算法、Dropout正则化和Batch Normalization等技术的引入，提升了深度学习模型的训练效率和泛化能力。

## 8、单独再提下Transformer架构

2017年，Vaswani等人在论文《Attention is All You Need》（《注意力是你要的一切》）提出了Transformer架构，这是自然语言处理（NLP）领域的一次革命性进展。与传统的RNN和LSTM不同，Transformer架构完全基于注意力机制（Attention Mechanism），可以更好地捕捉序列数据中的长距离依赖关系。

Transformer架构的核心组件是自注意力机制（Self-Attention），它允许模型在处理一个序列中的每个元素时，关注该序列中其他所有元素的相关性。Transformer的提出极大地提升了NLP任务的性能，如机器翻译、文本生成和问答系统。

## 9、OpenAI的发展

OpenAI早年是一个致力于推动和发展友好人工智能的非营利性的研究机构。成立于2015年，OpenAI的使命是确保人工智能技术造福全人类。OpenAI在AI研究中取得了许多重要成果，其中最著名的包括GPT（生成式预训练变换器）系列模型。

GPT系列模型基于Transformer架构，旨在通过大规模的无监督学习，生成高质量的自然语言文本。特别是GPT-3，具有1750亿参数，能够执行各种自然语言处理任务，如翻译、总结、对话等。

GPT-3展示了预训练大模型在多任务学习中的强大能力，推动了AI在自然语言理解和生成领域的前沿发展。此后，随着OpenAI的ChatGPT横空出世，更是激起了人们对AI的热情，AI的发展正是进入了大模型时代。

## 10、AI发展的主要里程碑

1. **1950年代**：艾伦·图灵提出图灵测试，标志着AI的概念初步形成。1956年的达特茅斯会议正式确立了AI作为一个学科。
2. **1960年代**：AI进入第一次发展期，有了一些初步的AI应用，如专家系统，但由于计算能力和数据限制，进展有限。
3. **1970-1980年代**：AI寒冬时期，研究资金减少，许多项目中止。
4. **1990年代**：统计方法在NLP中的应用，AI研究逐步复苏。
5. **2000年代**：机器学习和大数据的兴起，AI应用开始在实际中取得成功，如垃圾邮件过滤、图像识别等。
6. **2010年代**：深度学习的崛起，卷积神经网络（CNN）在图像识别领域取得突破。2012年，Hinton等人提出的深度卷积神经网络在ImageNet竞赛中取得显著成绩。
7. **2017年代**：Transformer架构的提出，极大地提升了NLP任务的性能。基于Transformer的预训练模型，如BERT、GPT等，通过在大规模语料上进行无监督预训练，然后在特定任务上进行微调，显著提升了NLP任务的性能。
8. **2020年代**：GPT-3的发布，展示了预训练大模型在多任务学习中的强大能力，推动了AI在自然语言理解和生成领域的前沿发展。
9. **2022年以后**：这后面的故事大家都清楚了，2022年年初OpenAI发布了GPT-3.5模型，2022年年底OpenAI发布了ChatGPT这一爆款应用。随后，各大科技公司纷纷重仓AI领域，进入了“百模大战”时代。

![](https://img.mangoant.top/blog/202408031633656.png)

## 11、AI的商业应用

### 商业应用

AI的商业应用范围广泛，涵盖了各个行业和领域。以下是一些典型的应用场景：

1. **医疗健康**：AI用于医疗图像分析、疾病预测和个性化治疗方案推荐，提升了医疗服务的效率和准确性。
2. **金融服务**：AI用于风险评估、欺诈检测和自动交易，帮助金融机构提升风控能力和运营效率。
3. **零售和电商**：AI用于个性化推荐、库存管理和需求预测，优化了供应链和客户体验。
4. **自动驾驶**：AI用于环境感知、路径规划和决策控制，推动了无人驾驶技术的发展。
5. **制造业**：AI用于预测性维护、质量检测和生产优化，提升了制造业的自动化和智能化水平。
6. **即将开启的各行各业**：其实除了以上行业，其余还有许多行业或者小众领域，都可以用AI赋能，但因为之前的AI开发模式和现在的开发模式不同，普通个体和企业很难参与其中。现在随着大模型的发展，一切都变了。后面，通过新的AI开发模式会有越来越多的行业被AI赋能。这也是开发者的机会。

### ChatGPT目前的应用

目前ChatGPT主要的领域还是在文本理解、文本生成、文生图、文生视频等。具体可以应用在以下领域，比如个人助手、办公、情感伴侣、软件研发助手、企业知识库等。

后续LLM会在AI Agent这个生态领域持续发力。大模型的本质还是自然语言理解和处理，它相当于一个超级大脑。但是想利用LLM给行业提质赋能，这个大脑还需要借助各种外部工具，比如工具、外部存储等等。那AI Agent就是实现这个提质赋能的最好技术生态。

## 12、开发者应该学习AI应用开发

AI 算法工程师原先是一个专门的工作。2022年之前，一个AI应用技术团队，需要前端开发、后端开发、大数据工程师和 AI 算法工程师这样一系列的工种。大部分人对于 AI 也只是有个概念性的了解，缺乏深入的认识。

现在，有了大语言模型，一切都变了，每个开发者都可以参与到AI的浪潮。目前AI领域开发者可以参与建设的有3个层面：算法层、训练大模型层、应用开发层。

对于普通开发者而言，AI应用层是比较容易破圈的。算法层需要高学历名校出生。训练大模型需要的数据和算力规模较大，只有大厂玩得起，目前这个情况去大厂也比较难。所以综合来看，开发者最容易破圈的方式就是做AI应用，就像当年的Android和iOS平台出来后，紧接着就是移动端应用的爆发。

### 为什么要去学习开发AI应用

为什么开发者要去学习开发AI应用？核心原因：**紧跟时代别掉队**。

说句实在话，打工人几乎都养成了`确定性的思维`，随着我们正在经历百年未有之大变局，一切都变得`不确定`了。不管是经济层面、科技层面、地缘政治层面，都变得非常的不确定性。我们普通人要敢于面对各种不确定性，这样才能在将来的危机中立于不败之地。

AI浪潮带来的变化对我们每个人来说都是巨大的冲击，许多人可能因此被冲垮。如果你不紧跟这个时代，那你就会掉队。***这个时代抛弃你的时候，连一声再见都不会说。***

在平时的工作中，我已经习惯于让 AI 帮我写代码，翻译英文资料，修改文章，指导我学习未知领域的知识，不知不觉AI已经成为了一个得力助手，并且使用AI已经成为了一种习惯。我不知道 AI 会不会让你失业，但是善用 AI 的个人和团队一定会有更高的效率和产出。

未来更是一个超级个体的时代，因为每个人都可以用AI给自己做能力加持，让自己充满无限可能。

由于 AI 大模型是一个新兴的领域，大多数人都在同一起跑线，对AI了解的越多，使用的越多，那在这个AI时代的机遇就会更多。所以，我建议每位开发者都应该深入学习相关知识，现在是一个对超级个体更好的时代，而且开发者是离这项技术最近的人，最有可能把握机会的人。

### AI应用的开发门槛降低了

在这一轮的 AI 浪潮里，开发 AI 应用的门槛大大降低了。在大模型出来之前，开发AI 应用是一个门槛比较高的事情。

- 需要开发者有不错的数学基础，熟悉微积分、线性代数和概率论；
- 需要掌握大量的机器学习和深度学习的知识，了解各种基础模型，比如逻辑回归、SVM、CNN、LSTM 等等的原理和实现；
- 需要学会使用各种机器学习的编程框架，比如 TensorFlow 或者 PyTorch。还需要买上一些价格不菲的 GPU 尝试训练模型；
- 需要理解在实际应用里锤炼机器学习的各种实战技巧和模型，比如各种各样的特征工程方式、Dropout 等正则化方法、超参数调优等等。

对于没有相关经验的人来说，不花上个一两年时间去学习和倒腾，很难做出一款实用的AI应用。但是现在不用了。

随着大模型的出现，即使没有任何机器学习的理论知识，开发者也只需要一两天时间，就能做出实用的 AI 应用。比如AI助手、AI语音对话、AI图片处理、企业知识库等等。

开发AI应用变得如此简单，对于有创意有想法的开发者来说，这绝对是一个非常好的时代。

## 13、转型AI应用开发的难点

其实许多开发者已经在学习AI给自己做能力加持了，但是人工智能本身确实复杂，令人生畏，可能直接从心理上就劝退了许多开发者。

但是，请注意！第一阶段，我们需要做的是，将注意力转向AI应用开发领域。将大模型的能力，结合我们自身多年的软件工程能力，去解决业务上的问题。

在做中学，没必要一开始就陷入AI知识的漩涡无法自拔。应该先做出些一些实用的AI应用，再逐步深入原理、最后才是啃经典教材和锻炼数学基础。

前期，你无需考虑机器学习和深度学习，无需考虑数学知识和模型，无需考虑GPU算力和存储问题。你只需要知道如何将大模型和AI Agent集成到现有的技术栈中，去开发一款实用的AI应用。

然后再去持续更新自己的AI知识体系，建立起更全面的AI认知。AI 技术的本质是机器学习，不过这些机器学习的原理并不要求你全部掌握，只掌握你最核心的技术原理就可以了，比如大语言模型技术原理中的 Transformer 架构、Word2Vec 等等。

大模型的一个很重要的能力，就是处理自然语言。只要有语言的地方，都能找到生成式 AI 的适用场景。就算不是为了企业去思考问题，单从成为超级个体的角度来看，这也是AI时代给我们的一个机会。

## 14、总结

人工智能的发展历程充满了挑战和突破。从最初的理论探索到今天的广泛应用，AI技术在不断演进和革新。机器学习、深度学习和Transformer架构等技术的突破，推动了AI从概念走向现实。

OpenAI等机构的努力，使得AI在自然语言处理等领域取得了显著进展。随着计算能力和数据资源的进一步提升，AI在未来将继续发挥更大的作用，推动各行各业的创新和发展。

作为程序开发者，掌握和应用AI技术将为你的职业发展带来新的机遇。希望本文能够帮助你更好地理解AI的发展脉络，为你在AI领域的探索提供一些启示。

希望你我都能紧跟时代，抓住机遇！